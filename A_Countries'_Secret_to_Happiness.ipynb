{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "colab": {
      "name": "A Countries' Secret to Happiness.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcEl8npv77h6"
      },
      "source": [
        "# A Countries' Secret to Happiness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs4NqLHo77h_"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaFBthBm77iB"
      },
      "source": [
        "Machine Learning Model for trying to answer the age-old question of - **what exactly makes us happy?**\n",
        "\n",
        "The World Happiness Report may be a point of interest survey of the state of worldwide bliss. The primary report was distributed in 2012, the second in 2013, the third in 2015, and the fourth within the 2016 Upgrade. The World Joy 2017, which positions 155 nations by their bliss levels, was discharged at the Joined together Countries at an occasion celebrating Universal Day of Joy on Walk 20th. \n",
        "\n",
        "![title](img/title.png.jpg)\n",
        "\n",
        "The report proceeds to pick up worldwide acknowledgment as governments, organizations and respectful society progressively utilize joy pointers to educate their policy-making choices. Driving specialists over areas – financial matters, brain research, overview investigation, national insights, wellbeing, open approach and more – depict how estimations of well-being can be used effectively to evaluate the advance of countries. \n",
        "\n",
        "The reports survey the state of bliss within the world nowadays and appear how the modern science of bliss clarifies individual and national varieties in bliss.\n",
        "\n",
        "There are six measurements taken per country for guaging the World Happiness Index. They consist of:\n",
        "\n",
        "1. GDP per Capita - Gross Domestic Product per capita for the countries\n",
        "\n",
        "2. Family - Satisfaction Rank of Family\n",
        "\n",
        "3. Life Expectancy - Avg. expected years to live\n",
        "\n",
        "4. Freedom - Perception of freedom quantified\n",
        "\n",
        "5. Generosity - Numerical value estimated based on the perception of Generosity experienced by poll takers in their country.\n",
        "\n",
        "6. Trust/Government Corruption - A quantification of the people's perceived trust in their governments.\n",
        "\n",
        "7. Dystopia Score - Score based on comparison to hypothetically the saddest country in the world.\n",
        "\n",
        "8. Dystopia Residual - Rank of any country in a particular year.\n",
        "\n",
        "The Happiness Score is a national average of the responses to the main life evaluation question asked in the Gallup World Poll (GWP), which uses the Cantril Ladder.\n",
        "\n",
        "The joy scores and rankings utilize information from the Gallup World Survey. The scores are based on answers to the most life evaluation address inquired within the survey. This address, known as the Cantril step, asks respondents to think of a step with the most excellent conceivable life for them being a 10 and the most exceedingly bad conceivable life being a and to rate their claim current lives on that scale. \n",
        "\n",
        "The scores are from broadly agent tests for the a long time 2013-2016 and utilize the Gallup weights to create the gauges agent. The columns taking after the bliss score assess the degree to which each of six variables – financial generation, social back, life anticipation, flexibility, nonattendance of debasement, and liberality – contribute to making life assessments higher in each nation than they are in\n",
        "\n",
        "\n",
        "**What is DYSTOPIA RESIDUAL?**\n",
        "\n",
        "Dystopia is a hypothetical country consisting of the least happy people. It was formed so as to create a benchmark to compare Happiness Scores of other countries with it. \n",
        "\n",
        "The Dystopia Residual is calculated as (Score of Dystopia+ Residual for the corresponding country). \n",
        "\n",
        "Here the Residual is a value generated for each country, which indicates if the 6 variables have under or over explained the life evaluations for each country for that particular year.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqVA47t777iD"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lczKoilK77iE"
      },
      "source": [
        "Given the data available per country to guage the Hapiness Index, the aim is to:\n",
        "    \n",
        "1. **Part A** - Analyze and understand which factors affect the Happiness Index Score of countries\n",
        "2. **Part B** - Analyze and understand the relationship between Terror Attacks and Happiness Index\n",
        "3. **Part C** - Create a Model to predict the Happiness Index of a Country\n",
        "4. **Part D** - To see how much Health contributes to the Happiness Index? With the current pandemic at hand, predicting COVID-19 Cases in the coming days for countries.\n",
        "5. **Part E** - Creating a Dashbord for viewing COVID-19 Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oCMFdXY77iF"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "## Ground work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OsQbguM77iG"
      },
      "source": [
        "### Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iLi4INU77iH"
      },
      "outputs": [],
      "source": [
        "!pip install bubbly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pmg4wq1077iJ"
      },
      "outputs": [],
      "source": [
        "!conda install libpython m2w64-toolchain -c msys2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80b5BkB177iK"
      },
      "outputs": [],
      "source": [
        "!pip install pystan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9lOA1Vo77iL"
      },
      "outputs": [],
      "source": [
        "!pip install fbprophet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReuO1bG-77iL"
      },
      "outputs": [],
      "source": [
        "# importing the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "from IPython.display import HTML\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import json\n",
        "import altair as alt\n",
        "from  altair.vega import v5\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.offline as py\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import plotly.graph_objs as go\n",
        "init_notebook_mode(connected = True)\n",
        "from bubbly.bubbly import bubbleplot\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from fbprophet import Prophet\n",
        "from fbprophet.plot import plot_plotly, plot_components_plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EANPhmf877iM"
      },
      "source": [
        "### Loading Happiness Index Reports (2015-2020) from Sustainable Development Solutions Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYKdZIpu77iN"
      },
      "outputs": [],
      "source": [
        "#loading individual dataset reports for the years from 2015-2020\n",
        "happiness_df_2015 = pd.read_csv(\"data/2015_report.csv\")\n",
        "happiness_df_2016 = pd.read_csv(\"data/2016_report.csv\")\n",
        "happiness_df_2017 = pd.read_csv(\"data/2017_report.csv\")\n",
        "happiness_df_2018 = pd.read_csv(\"data/2018_report.csv\")\n",
        "happiness_df_2019 = pd.read_csv(\"data/2019_report.csv\")\n",
        "happiness_df_2020 = pd.read_csv(\"data/2020_report.csv\")\n",
        "\n",
        "#adding column in each dataset to represent year\n",
        "happiness_df_2015['year'] = 2015\n",
        "happiness_df_2016['year'] = 2016\n",
        "happiness_df_2017['year'] = 2017\n",
        "happiness_df_2018['year'] = 2018\n",
        "happiness_df_2019['year'] = 2019\n",
        "happiness_df_2020['year'] = 2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4coj2Pc77iN"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "#merging all dataframes into one dataframe\n",
        "df = df.append(happiness_df_2015)\n",
        "df = df.append(happiness_df_2016)\n",
        "df = df.append(happiness_df_2017)\n",
        "df = df.append(happiness_df_2018)\n",
        "df = df.append(happiness_df_2019)\n",
        "df = df.append(happiness_df_2020)\n",
        "\n",
        "#replacing na with 0\n",
        "df = df.fillna(0)\n",
        "targets = ['Low', 'Low-Mid', 'Top-Mid', 'Top']\n",
        "df[\"target\"] = pd.qcut(df['happiness_score'], len(targets), labels=targets)\n",
        "df[\"target_n\"] = pd.qcut(df['happiness_score'], len(targets), labels=range(len(targets)))\n",
        "dff = df.drop(['country','continent','target','target_n','year'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JYci8Ud77iO"
      },
      "source": [
        "## Part A\n",
        "\n",
        "To Analyze and understand which factors affect the Happiness Index Score of countries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOpm1TQE77iO"
      },
      "source": [
        "## Explaratory Data Analysis\n",
        "\n",
        "The objective here is to look through the datasets and perform some basic analysis to understand and guage insights. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3n9-wss77iP"
      },
      "source": [
        "### A look into Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9RfNIwW77iP"
      },
      "source": [
        "*The Spearman's Rank Correlation Coefficient is used to discover the strength of a link between two sets of data.*\n",
        "\n",
        "+ If you have two numeric variables that are not linearly related, or if one or both of your variables are ordinal variables, you can still measure the strength and direction of their relationship using a non-parametric correlation statistic. \n",
        "\n",
        "+ The most common of these is the Spearman rank correlation coefficient, ρ, which considers the ranks of the values for the two variables.Spearman’s correlation is equivalent to calculating the Pearson correlation coefficient on the ranked data. So ρ will always be a value between -1 and 1. \n",
        "\n",
        "+ The further away ρ is from zero, the stronger the relationship between the two variables. The sign of ρ corresponds to the direction of the relationship. If it is positive, then as one variable increases, the other tends to increase. If it is negative, then as one variable increases, the other tends to decrease.\n",
        "\n",
        "+ You use Spearman’s correlation if your data have a non-linear relationship (like an exponential relationship) or you have one or more outliers. However, Spearman’s correlation is only appropriate if the relationship between your variables is monotonic, meaning that as one variable increases, the other tends to either increase or decrease (not both)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj7Efiss77iQ"
      },
      "outputs": [],
      "source": [
        "spearman_cormatrix= df.corr(method='spearman')\n",
        "spearman_cormatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji5GN3TC77iQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "ax = sns.heatmap(spearman_cormatrix, vmin=-1, vmax=1, \n",
        "            center=0, cmap=\"viridis\", annot=True)\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.5, top - 0.5);\n",
        "plt.title(\"Continuous Matrix of Spearman Correlation\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TyZXAtG77iQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "ax = sns.heatmap(spearman_cormatrix, vmin=-.25, vmax=1, center=0, cmap=\"Paired\", annot=True)\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.5, top - 0.5);\n",
        "plt.title(\"Binned Matrix of Spearman Correlation\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPTW8JwJ77iR"
      },
      "source": [
        "**Inference**: From the above matrixes, it seems like *Health*, *GDP Per Capita* and *freedom* are the top 3 factors that correlate with happiness index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGd7xOla77iR"
      },
      "source": [
        "#### Univariate Analysis\n",
        "\n",
        "This type of analysis consists of use of single variable. The analysis of univariate data is thus the simplest form of analysis since the information deals with only one quantity that changes. It does not deal with causes or relationships and the main purpose of the analysis is to describe the data and find patterns that exist within it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLV_Rtxq77iS"
      },
      "outputs": [],
      "source": [
        "#univariate analysis\n",
        "numerics = ['happiness_score', 'gdp_per_capita', 'health', 'freedom', 'generosity',\n",
        "       'government_trust']\n",
        "color = ['r','blue','g','y','dodgerblue','orange']\n",
        "\n",
        "plt.figure(figsize = (18,10))\n",
        "plt.suptitle(\"Univariate Analysis of all Factors\")\n",
        "for i in numerics:\n",
        "    plt.subplot(2,3,numerics.index(i)+1)\n",
        "    plt.scatter(np.arange(df.shape[0]),df[i], color = color[numerics.index(i)])\n",
        "    plt.title(i)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvyM19OE77iS"
      },
      "source": [
        "#### Bivariate Analysis\n",
        "\n",
        "This type of analysis involves two different variables. The analysis of this type of data deals with causes and relationships and the analysis is done to find out the relationship among the two variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgNFVoEi77iS"
      },
      "outputs": [],
      "source": [
        "#Bivariate Analysis\n",
        "plt.figure(figsize=(18,20))\n",
        "sns.set_context(\"paper\", rc={\"axes.labelsize\":15})\n",
        "sns.pairplot(df);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0GzCeW-77iS"
      },
      "source": [
        "**Inference**:\n",
        "\n",
        "From the above plot, we can infer that there seems to be a: <br/>\n",
        "**Linear Relationship:** happiness_score v/s gdp_per_capita, happiness_score v/s health, happiness_score v/s freedom <br/>\n",
        "**Non-Linear Relationship:** happiness_score v/s gerosity, happiness_score v/s government_trust"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9w83JES77iT"
      },
      "source": [
        "### Performing ANOVA test between predictors and response variable to guage how significantly it affects the scoring\n",
        "\n",
        "Analysis of Variance is a statistical method, used to check the means of two or more groups that are significantly different from each other. It assumes Hypothesis as\n",
        "H0: Means of all groups are equal.\n",
        "H1: At least one mean of the groups are different.\n",
        "    \n",
        "+ If the distributions overlap or close, the grand mean will be similar to individual means whereas if distributions are far, the grand mean and individual means differ by larger distance.\n",
        "+ It refers to variations between the groups as the values in each group are different. \n",
        "+ So in ANOVA, we will compare Between-group variability to Within-group variability.\n",
        "+ ANOVA uses F-test check if there is any significant difference between the groups. \n",
        "+ If there is no significant difference between the groups that all variances are equal, the result of ANOVA’s F-ratio will be close to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6dNFe_y77iT"
      },
      "outputs": [],
      "source": [
        "#performing ANOVA test\n",
        "k_best = SelectKBest(f_classif,k=\"all\")\n",
        "k_best.fit_transform(dff.drop('happiness_score', axis=1), dff['happiness_score'])\n",
        "p_values = pd.DataFrame({'column': dff.drop('happiness_score', axis=1).columns, 'p_value': k_best.pvalues_}).sort_values('p_value')\n",
        "best_predictors = p_values[p_values['p_value'] < .05].iloc[:10,:]['column'].to_list()\n",
        "print(\"The best predictors of Happiness Index are: \")\n",
        "print(str(best_predictors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNlMsS1_77iT"
      },
      "source": [
        "Two of the aspects coming out of ANOVA test belong to the correlation inference i.e GDP per capita and health. Apart from that, it seems like government trust and family also play quite a significant role in realizing the happiness score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdbQjU_m77iU"
      },
      "source": [
        "### Looking at all countries and their ranks in Happiness Index Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFrfOQP977iU"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(df, x='country', y='happiness_score',color='happiness_score',height=800)\n",
        "fig.update_layout(title='Arrangement of countries in descending order of Happiness Score',titlefont_size=20)\n",
        "\n",
        "py.iplot(fig, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6weuSZdQ77iU"
      },
      "source": [
        "**Inference**: Clearly Norwary seems to the top country scoring in Happiness Index. It is not surprising since European Countries have better living conditions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPpFS4JL77iU"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "x0 = df['gdp_per_capita'].values\n",
        "x1 = df['health'].values\n",
        "x2 = df['government_trust'].values\n",
        "x3 = df['dystopia_residual'].values\n",
        "\n",
        "fig.add_trace(go.Histogram(x=x0))\n",
        "fig.add_trace(go.Histogram(x=x1))\n",
        "fig.add_trace(go.Histogram(x=x2))\n",
        "fig.add_trace(go.Histogram(x=x3))\n",
        "\n",
        "# Overlay both histograms\n",
        "fig.update_layout(barmode='overlay', title=\"Distribution of GDP, Health, Government, Dystopia\")\n",
        "# Reduce opacity to see both histograms\n",
        "fig.update_traces(opacity=1)\n",
        "py.iplot(fig, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dd6REMg77iU"
      },
      "source": [
        "### Happiness with regards to Generosity and Economy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdiRTSeI77iV"
      },
      "outputs": [],
      "source": [
        "figure = bubbleplot(dataset = df, x_column = 'happiness_score', y_column = 'generosity', \n",
        "    bubble_column = 'country', size_column = 'gdp_per_capita', color_column = 'continent', \n",
        "    x_title = \"Happiness Score\", y_title = \"Generosity\", title = 'Happiness vs Generosity vs Economy',\n",
        "    x_logscale = False, scale_bubble = 1, height = 650)\n",
        "\n",
        "py.iplot(figure, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uO3jZ1E77iV"
      },
      "source": [
        "**Inference**: The farther right side bubbless are mostly contries in the European Continents. Clearly they have better GDP Per capita. Surprisingly Europeans countries score average on Generosity(Asian countries have highest generosity) but have the most Happiness Score rankings. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-0VUUCJ77iV"
      },
      "source": [
        "### Happiness with regards to Health and Economy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Cb3aJZI77iW"
      },
      "outputs": [],
      "source": [
        "figure = bubbleplot(dataset = df, x_column = 'happiness_score', y_column = 'health', \n",
        "    bubble_column = 'country', size_column = 'gdp_per_capita', color_column = 'continent', \n",
        "    x_title = \"Happiness Score\", y_title = \"Health\", title = 'Happiness vs Health vs Economy',\n",
        "    x_logscale = False, scale_bubble = 1, height = 650)\n",
        "\n",
        "py.iplot(figure, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jOD9PvK77iW"
      },
      "source": [
        "**Inference**: The farther right side bubbles are mostly contries in the European Continents. Clearly they have better Health score as well since they are present on top. The lowest health scores mostly consists of African and Asian countries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5PNfQk277iX"
      },
      "source": [
        "### Happiness with regards to Family and Economy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVC0zH3p77iX"
      },
      "outputs": [],
      "source": [
        "figure = bubbleplot(dataset = df, x_column = 'happiness_score', y_column = 'family', \n",
        "    bubble_column = 'country', size_column = 'gdp_per_capita', color_column = 'continent', \n",
        "    x_title = \"Happiness Score\", y_title = \"Family\", title = 'Happiness vs Family vs Economy',\n",
        "    x_logscale = False, scale_bubble = 1, height = 650)\n",
        "\n",
        "py.iplot(figure, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mseubjs477iX"
      },
      "source": [
        "**Inference:** \n",
        "\n",
        "The farther right side bubbless are mostly contries in the European Continents. Clearly they have better Family ratings. The most unsatisfied family rankings is actually mixture of mostly African, South American,Asian and a few European countries & North American countries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K4O-Dzn77iX"
      },
      "source": [
        "### Happiness with regards to Govt Trust and Economy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3_8hZQS77iX"
      },
      "outputs": [],
      "source": [
        "figure = bubbleplot(dataset = df, x_column = 'happiness_score', y_column = 'government_trust', \n",
        "    bubble_column = 'country', size_column = 'gdp_per_capita', color_column = 'continent', \n",
        "    x_title = \"Happiness Score\", y_title = \"Government Trust\", title = 'Happiness vs Government Trust vs Economy',\n",
        "    x_logscale = False, scale_bubble = 1, height = 650)\n",
        "\n",
        "py.iplot(figure, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dMdGFra77iY"
      },
      "source": [
        "**Inference:** \n",
        "\n",
        "Most countries rank low on government trust giving us insights into how most of the world population doesn't necessarily trust it's governments despite the ovearching push of democracy to be adoptee. High government trust countries are Rwanda and obvious countries of Sinagpore, New Zealand, Finland."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaFQVayW77iY"
      },
      "source": [
        "### World-wide View of Countries with regards to Generosity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI6ma4wc77iY"
      },
      "outputs": [],
      "source": [
        "#plotting\n",
        "trace1 = [go.Choropleth(\n",
        "               colorscale = 'Portland',\n",
        "               locationmode = 'country names',\n",
        "               locations = df['country'],\n",
        "               text = df['country'], \n",
        "               z =df['generosity'],\n",
        "               )]\n",
        "\n",
        "layout = dict(title = 'Overview of World Generosity',\n",
        "                  geo = dict(\n",
        "                      showframe = True,\n",
        "                      showocean = True,\n",
        "                      showlakes = True,\n",
        "                      showcoastlines = True,\n",
        "                      projection = dict(\n",
        "                          type = 'natural earth'       )))\n",
        "\n",
        "\n",
        "fig = go.Figure(data = trace1, layout = layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmN-CwAL77iY"
      },
      "outputs": [],
      "source": [
        "trace1 = [go.Choropleth(\n",
        "               colorscale = 'Cividis',\n",
        "               locationmode = 'country names',\n",
        "               locations = df['country'],\n",
        "               text = df['country'], \n",
        "               z =df['family'],\n",
        "               )]\n",
        "\n",
        "layout = dict(title = 'Overview of World Family Satisfaction',\n",
        "                  geo = dict(\n",
        "                      showframe = True,\n",
        "                      showocean = True,\n",
        "                      showlakes = True,\n",
        "                      showcoastlines = True,\n",
        "                      projection = dict(\n",
        "                          type = 'natural earth'       )))\n",
        "\n",
        "\n",
        "fig = go.Figure(data = trace1, layout = layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIOUIuIu77iY"
      },
      "outputs": [],
      "source": [
        "trace1 = [go.Choropleth(\n",
        "               colorscale = 'tropic',\n",
        "               locationmode = 'country names',\n",
        "               locations = df['country'],\n",
        "               text = df['country'], \n",
        "               z =df['government_trust'],\n",
        "               )]\n",
        "\n",
        "layout = dict(title = 'Overview of World Government Trust',\n",
        "                  geo = dict(\n",
        "                      showframe = True,\n",
        "                      showocean = True,\n",
        "                      showlakes = True,\n",
        "                      showcoastlines = True,\n",
        "                      projection = dict(\n",
        "                          type = 'natural earth'       )))\n",
        "\n",
        "\n",
        "fig = go.Figure(data = trace1, layout = layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4unVfO377iZ"
      },
      "outputs": [],
      "source": [
        "trace1 = [go.Choropleth(\n",
        "               colorscale = 'Portland',\n",
        "               locationmode = 'country names',\n",
        "               locations = df['country'],\n",
        "               text = df['country'], \n",
        "               z =df['gdp_per_capita'],\n",
        "               )]\n",
        "\n",
        "layout = dict(title = 'Overview of world Economy',\n",
        "                  geo = dict(\n",
        "                      showframe = True,\n",
        "                      showocean = True,\n",
        "                      showlakes = True,\n",
        "                      showcoastlines = True,\n",
        "                      projection = dict(\n",
        "                          type = 'natural earth'       )))\n",
        "\n",
        "\n",
        "fig = go.Figure(data = trace1, layout = layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkzgN7sr77iZ"
      },
      "outputs": [],
      "source": [
        "trace1 = [go.Choropleth(\n",
        "               colorscale = 'rainbow',\n",
        "               locationmode = 'country names',\n",
        "               locations = df['country'],\n",
        "               text = df['country'], \n",
        "               z =df['happiness_score'],\n",
        "               )]\n",
        "\n",
        "layout = dict(title = 'Overview of World Happiness Score',\n",
        "                  geo = dict(\n",
        "                      showframe = True,\n",
        "                      showocean = True,\n",
        "                      showlakes = True,\n",
        "                      showcoastlines = True,\n",
        "                      projection = dict(\n",
        "                          type = 'natural earth'       )))\n",
        "\n",
        "\n",
        "fig = go.Figure(data = trace1, layout = layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u6YXR3277iZ"
      },
      "source": [
        "### Trend of Happiness Over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYv4lSc277iZ"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig=px.line(df,x='year',y='happiness_score',color='country',template=\"ggplot2\")\n",
        "py.iplot(fig, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfpt8Lkj77ia"
      },
      "outputs": [],
      "source": [
        "fig = px.pie(df, values='gdp_per_capita', names='continent', title='Continent Wise Contribution to Worl Economy',height=650)\n",
        "py.iplot(fig, config={'scrollzoom': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaIYlhTV77ia"
      },
      "source": [
        "From the chart we can notice that the continent of Europe has a good score of GDP per capita, compared to others. Australian countries contribute the least to global GDP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PDX6kBE77ib"
      },
      "source": [
        "# Part B \n",
        "\n",
        "Analyze and understand the relationship between Terror Attacks and Happiness Index\n",
        "\n",
        "### Thoughts/ Motive\n",
        "\n",
        "One of the things that intrigued us terrorism across the world. With wars and conflicts happening on a day to day basis, I really wanted to understand to what extent terrorism plays a role in happiness index. For this I combined two datasets - the Happiness Datasets and the World Terrorism dataset from Global Terrorism Database(GTD).\n",
        "\n",
        "In the datasets, only the count of terror attacks was considered and not other information such as text based data surrounding the context of what happpened, names of the weapons used and so on since that would delve into NLP.  \n",
        "The future work in scope is using NLP to also analyse the datasets in order to better guage the relationship between happiness and terrorism. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeeKtI_V77ib"
      },
      "source": [
        "# Processing the Datasets\n",
        "\n",
        "Now that we have seen EDA on Happiness Index, what about terror attacks? Clearly the factors mentioned above are not sufficient enough to explain true happiness. So to see how terror attacks combine with happiness index and to answer the question if there is a correlation present. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GhyKn_M77ib"
      },
      "source": [
        "### Below Cells take time to execute due to large dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ePSIPWm77ib"
      },
      "source": [
        "### Terrorism Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLP2iuHb77ic"
      },
      "outputs": [],
      "source": [
        "# Loading the Global Terrorism Databse\n",
        "df = pd.read_excel(\"data/globalterrorismdb_0919dist.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFThfvzv77ic"
      },
      "outputs": [],
      "source": [
        "# Taking a look at the data\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ9nZ9nf77ic"
      },
      "outputs": [],
      "source": [
        "# taking just the years of which we have terrorism data\n",
        "df_select = df.loc[(df[\"iyear\"]==2015) | (df[\"iyear\"]==2016) | (df[\"iyear\"]==2017) | (df[\"iyear\"]==2018)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG8HNBD477ic"
      },
      "outputs": [],
      "source": [
        "# getting the number of terror_attacks countrywise sorted by year\n",
        "temp = df_select.pivot_table(index='country_txt', \n",
        "                     columns='iyear', \n",
        "                     values='attacktype1',\n",
        "                     fill_value=0, \n",
        "                     aggfunc='count').unstack().to_frame(name=\"terror_attacks\").reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8H4wIEE77ic"
      },
      "source": [
        "### Happiness Index Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnVOOhM277id"
      },
      "outputs": [],
      "source": [
        "# Combining all the happiness index dataset\n",
        "all_files = glob.glob(\"*.csv\")\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    cdf = pd.read_csv(filename, index_col=None, header=0)\n",
        "    cdf[\"Year\"] = [i for i in [int(filename.split(\"_\")[0])] for _ in range(len(cdf))]\n",
        "    cdf.replace({\"Congo (Brazzaville)\":\"Democratic Republic of the Congo\",\"Congo (Kinshasa)\":\"Republic of Congo\"}, inplace=True)\n",
        "    cdf.sort_values(\"country\", inplace=True)\n",
        "    li.append(cdf)\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBSopodS77id"
      },
      "outputs": [],
      "source": [
        "frame.drop([\"family\", \"dystopia_residual\", \"social_support\", \"continent\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFzFlFjk77id"
      },
      "outputs": [],
      "source": [
        "enc = LabelEncoder()\n",
        "enc.fit(frame.country)\n",
        "frame[\"country_id\"] = enc.transform(frame.country)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDJt5Ik177id"
      },
      "source": [
        "### Combining the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J3LAKoW77ie"
      },
      "outputs": [],
      "source": [
        "final_df = pd.merge(frame, temp, left_on=[\"Year\", \"country\"], right_on=[\"iyear\", \"country_txt\"], how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igC6rhD277ie"
      },
      "outputs": [],
      "source": [
        "final_df = final_df.dropna(axis=0, how='any')\n",
        "final_df.drop([\"country_txt\", \"iyear\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJym7sU477ie"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv(\"data/final_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHGyZQFx77ie"
      },
      "source": [
        "# Exploratory Data Analysis on Combines Dataset with Terrorism  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "51vwd7qP77if"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/final_dataset.csv\").drop([\"Unnamed: 0\", \"country_id\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_a0ATQ77if"
      },
      "outputs": [],
      "source": [
        "#univariate analysis\n",
        "numerics = ['happiness_score', 'gdp_per_capita', 'health', 'freedom', 'generosity',\n",
        "       'government_trust', 'terror_attacks']\n",
        "\n",
        "color = ['r','blue','g','y','dodgerblue','orange','pink']\n",
        "\n",
        "plt.figure(figsize = (18,10))\n",
        "plt.suptitle(\"Univariate Analysis of all Factors\")\n",
        "for i in numerics:\n",
        "    plt.subplot(3,3,numerics.index(i)+1)\n",
        "    plt.scatter(np.arange(df.shape[0]),df[i], color = color[numerics.index(i)])\n",
        "    plt.title(i)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oFLvebt77if"
      },
      "source": [
        "We can see that there are some countries which go through alot of terrorist attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "531laWwa77if"
      },
      "outputs": [],
      "source": [
        "#Bivariate Analysis\n",
        "sns.set_context(\"paper\", rc={\"axes.labelsize\":15})\n",
        "sns.pairplot(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3pwcbvi77if"
      },
      "source": [
        "There seems to be a: <br/>\n",
        "**Linear Relationship:** happiness_score v/s gdp_per_capita, happiness_score v/s health, happiness_score v/s freedom <br/>\n",
        "**Non-Linear Relationship:** happiness_score v/s gerosity, happiness_score v/s government_trust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr1JNs-U77ig"
      },
      "outputs": [],
      "source": [
        "#Calculating the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "#Plotting it as a heatmap\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap( corr, annot = True, cmap = 'coolwarm')\n",
        "bottom, top = plt.ylim()\n",
        "plt.ylim(bottom + 0.5, top - 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAN09Sgo77ig"
      },
      "outputs": [],
      "source": [
        "trace1 = [go.Choropleth(\n",
        "               colorscale = 'blackbody',\n",
        "               locationmode = 'country names',\n",
        "               locations = df['country'],\n",
        "               text = df['country'], \n",
        "               z =df['terror_attacks'],\n",
        "               )]\n",
        "\n",
        "layout = dict(title = 'Overview of Terror Attack Rates',\n",
        "                  geo = dict(\n",
        "                      showframe = True,\n",
        "                      showocean = True,\n",
        "                      showlakes = True,\n",
        "                      showcoastlines = True,\n",
        "                      projection = dict(\n",
        "                          type = 'natural earth'       )))\n",
        "\n",
        "\n",
        "fig = go.Figure(data = trace1, layout = layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtV8P_wy77ig"
      },
      "source": [
        "**Inference**:\n",
        "\n",
        "With the data that we have, there doesn't seem to be much correlation between terror attacks and happienss index. We would need more data to come to a singificant conclusion as to how terrorism really affects the happiness index. Perhaps another factors that would allow us to further understand the happiness index would be war conditions. Countries like Syria and Palestine, are in critical war zones which would make their living condtions poor and hence affecting the happiness index. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vdmj3Af77ig"
      },
      "source": [
        "## Part C \n",
        "\n",
        "To create a Model to Predict Happiness Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NobwNjV77ih"
      },
      "source": [
        "# Predicting happiness Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncvWfOHf77ih"
      },
      "outputs": [],
      "source": [
        "# Splitting into predictors and response variable\n",
        "X = df.drop([\"happiness_score\",\"country\"], axis=1)\n",
        "y = df[\"happiness_score\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ478GUe77ih"
      },
      "outputs": [],
      "source": [
        "# Scaling the predicators to make them between 0 and 1\n",
        "scale = MinMaxScaler()\n",
        "X_scaled = scale.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-lcq0--77ih"
      },
      "outputs": [],
      "source": [
        "# Splitting into test and train sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkpRiVBL77ii"
      },
      "outputs": [],
      "source": [
        "degrees = range(1, 7)\n",
        "alphas = [1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100, 1000]\n",
        "best_alpha = []\n",
        "for degree in degrees:\n",
        "    training_error, validation_error = [], []\n",
        "    X_poly_train = PolynomialFeatures(degree).fit_transform(X_train)\n",
        "    for alpha in alphas:\n",
        "        lreg = Lasso(alpha=alpha, fit_intercept=False, max_iter=2000)\n",
        "        cv = cross_validate(lreg, X_poly_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
        "        validation_error.append(-np.mean(cv['test_score']))\n",
        "        training_error.append(-np.mean(cv['train_score']))\n",
        "    best_a = alphas[validation_error.index(min(validation_error))]\n",
        "    best_alpha.append([best_a, min(validation_error), min(training_error)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1Pq19xK77ii"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "plt.plot(degrees, np.array(best_alpha)[:, 1], label = 'validation_error')\n",
        "plt.plot(degrees, np.array(best_alpha)[:, 2], c='red', label = 'training_error')\n",
        "plt.xlabel(\"Degrees\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Looking at which degree Gave us the Least MSE Score\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEhQrq8h77ii"
      },
      "outputs": [],
      "source": [
        "# Training the best model\n",
        "best_degree = degrees[best_alpha.index(min(best_alpha, key=lambda x:x[1]))]\n",
        "best_alphav = min(best_alpha, key=lambda x:x[1])[0]\n",
        "\n",
        "X_poly_train = PolynomialFeatures(best_degree).fit_transform(X_train)\n",
        "X_poly_test = PolynomialFeatures(best_degree).fit_transform(X_test)\n",
        "\n",
        "lreg = Lasso(alpha=best_alphav, fit_intercept=False, max_iter=2000)\n",
        "lreg.fit(X_poly_train, y_train)\n",
        "\n",
        "#Testing the Model\n",
        "y_pred_test = lreg.predict(X_poly_test)\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "#Model performance MEtrics\n",
        "print(\"The MSE value of the model is: \", np.round(mse,2))\n",
        "print(\"The R2 score of the model is : \", np.round(r2,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVf8cEQn77ij"
      },
      "source": [
        "We used Lasso Regression with the degree of 6 to perform Polynomial Lasso Regression in order to predict the Happiness Score. \n",
        "\n",
        "**The MSE value for Lasso Regression is 0.25 and the R2 Score is 0.82 which is pretty satisfactory.**\n",
        "\n",
        "#### Why did we use Lasso Regression?\n",
        "\n",
        "+ We understood that Lasso tends to do well if there are a small number of significant parameters and the others are close to zero (ergo: when only a few predictors actually influence the response). This was the case where the parameters no. was relatively small hence this seemed like the good approach to take. Ridge works well if there are many large parameters of about the same value (ergo: when most predictors impact the response).\n",
        "+ Lasso, or Least Absolute Shrinkage and Selection Operator, is quite similar conceptually to ridge regression. It also adds a penalty for non-zero coefficients, but unlike ridge regression which penalizes sum of squared coefficients (the so-called L2 penalty), lasso penalizes the sum of their absolute values (L1 penalty). As a result, for high values of λ, many coefficients are exactly zeroed under lasso, which is never the case in ridge regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw3glhLW77ij"
      },
      "outputs": [],
      "source": [
        "hap_regr = MLPRegressor(hidden_layer_sizes=(100, 50, 25), solver='adam', random_state=1, max_iter=500)\n",
        "hap_regr.fit(X_train, y_train)\n",
        "score = hap_regr.score(X_test, y_test)\n",
        "pred = hap_regr.predict(X_test)\n",
        "mse = mean_squared_error(y_test,pred)\n",
        "print(\"The MSE value of our model is: \", np.round(mse,2))\n",
        "print(\"The R2 score of our model is : \", np.round(score,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hf-exe77ij"
      },
      "source": [
        "**What did we do in MLP Regressor?**\n",
        "\n",
        "+ Our choice of multiple number of layers here is to depict non-linearity in the model. Multiple number of layers lead to non-linearity, but excess number of layers may lead to overfitting of the model.\n",
        "+ Experimenting and trying out multiple combinations of layers and neurons, three layers with depicted neurons turned out to be suitable for our model.\n",
        "+ Also, we used the default Activation Function, ReLu because of our model being a Linear Regression Model and ReLu fits the best for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceMQV5Cn77ij"
      },
      "source": [
        "**Our MSE value for MLP Regressor is 0.26 and our R2 Score is 0.82 which is pretty much the same as Lasso Regression.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUp_2MoC77ij"
      },
      "source": [
        "# Predicting Terrorist attacks\n",
        "\n",
        "We also tried experimenting witht the variables we have from the happiness dataset to see if we can satisfactorily predict no. of terrorist attacks likely to happen. \n",
        "\n",
        "Of course the model does not have the best performance because we understand that there are more factors that affect the outcome. \n",
        "\n",
        "**Our future work here is to get more external factors relating to what sparks terrorim attacks and create model to allow for better risk handling.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp7o9wGU77ik"
      },
      "outputs": [],
      "source": [
        "# Making a terrorism index where countries with terror_attacks 100 or above will have a value 1\n",
        "df[\"terror_attacks\"][df[\"terror_attacks\"]>100]=100\n",
        "\n",
        "# doing non-linear scaling\n",
        "df[\"terror_attacks\"] = np.sqrt(df[\"terror_attacks\"])\n",
        "scaler = MinMaxScaler()\n",
        "df[\"terror_attacks\"] = scaler.fit_transform(df[[\"terror_attacks\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGqg9VPA77ik"
      },
      "outputs": [],
      "source": [
        "# Assigning predictors and response variables\n",
        "X = df.drop([\"terror_attacks\",'country'], axis=1)\n",
        "y = df[\"terror_attacks\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSr8_WgM77ik"
      },
      "outputs": [],
      "source": [
        "# Splitting into test and train sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ4kctor77ik"
      },
      "outputs": [],
      "source": [
        "# Using Neural Nets for a best possible prediction\n",
        "regr = MLPRegressor(hidden_layer_sizes=(100, 50, 25), solver='adam', random_state=1, max_iter=500)\n",
        "regr.fit(X_train, y_train)\n",
        "regr.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpznX5J77ik"
      },
      "source": [
        "Clearly, the model is not performing well here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj70-v1e77il"
      },
      "source": [
        "## Part D\n",
        "\n",
        "To see how much Health contributes to the Happiness Index? With the current pandemic at hand, predicting COVID-19 Cases in the coming days for countries.\n",
        "\n",
        "### Thoughts\n",
        "\n",
        "From Part A, we have realized that Health does play a major role in a country's happiness score. With the current pandemic at hand, we were motivated to look at COVID cases and forecast the upcoming cases. We wanted to compare the COVID data with the happiness index data, however, we felt that it would not give the right results since the happiness index data of 2020 is from the months of January-February when there was not much COVID health crisis happening. \n",
        "\n",
        "However, in pursuit of excitement and interest, we decided to go forth to do a basic forecasting model on COVID-19 dataset using fbprophet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64OzKXvi77il"
      },
      "source": [
        "### What and Why Prophet?\n",
        "\n",
        "Prophet is Facebooks'open source time series prediction. Prophet decomposes time series into trend, seasonality and holiday. It has intuitive hyper parameters which are easy to tune.\n",
        "\n",
        "**Prophet time series = Trend + Seasonality + Holiday + error**\n",
        "\n",
        "Trend models non periodic changes in the value of the time series. Seasonality is the periodic changes like daily, weekly, or yearly seasonality. Holiday effect which occur on irregular schedules over a day or a period of days. Error terms is what is not explained by the model.\n",
        "\n",
        "We believe that the advantages of using Prophet are:\n",
        "+ Accommodates seasonality with multiple periods\n",
        "+ Prophet is resilient to missing values\n",
        "+ Best way to handle outliers in Prophet is to remove them\n",
        "+ Fitting of the model is fast\n",
        "+ Intuitive hyper parameters which are easy to tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYI4c36G77il"
      },
      "outputs": [],
      "source": [
        "country='India'       # User Input 1\n",
        "column='new_cases'    # User Input 2\n",
        "forecast_period=30    # User Input 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lAQi_zF77il"
      },
      "outputs": [],
      "source": [
        "#Reading DataFrames\n",
        "df = pd.read_csv('data/owid-covid-data.csv')\n",
        "df = df[df['location']!='Hong Kong']\n",
        "df['date'] = pd.to_datetime(df['date'],utc=False)\n",
        "data=df[df['location']==country][['date',column]].rename(columns={\"date\":\"ds\",column:\"y\"})\n",
        "\n",
        "#Initializing Model\n",
        "m = Prophet()\n",
        "\n",
        "#Fitting Data\n",
        "m.fit(data)\n",
        "\n",
        "#Making Future Predictions\n",
        "future=model.make_future_dataframe(periods=forecast_period)\n",
        "forecast = m.predict(future)\n",
        "\n",
        "#Visualizing Forecast\n",
        "plot_plotly(m, forecast).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzHkj-e877im"
      },
      "outputs": [],
      "source": [
        "plot_components_plotly(m,forecast).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLKsKSJ177im"
      },
      "outputs": [],
      "source": [
        "from fbprophet.diagnostics import cross_validation\n",
        "from fbprophet.diagnostics import performance_metrics\n",
        "\n",
        "cross_validation_results = cross_validation(m, initial='210 days', period='15 days', horizon='70 days')\n",
        "cross_validation_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an_x-qnc77im"
      },
      "outputs": [],
      "source": [
        "performance_metrics_results = performance_metrics(cross_validation_results)\n",
        "performance_metrics_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovvsrZjO77in"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "+ The data factors being used for calculating the Happiness Index of the countries is not holistic and inclusive. There are other factors to also be considered. GDP per capita seems to be a skewed figure itself and the limitations that GDP poses is highly likely to bias the happiness score.\n",
        "\n",
        "+ We did not find much correlation between no. of terror attacks and happiness index of a country. However, we believe we need to consider more factors & influences pertaining to terrorism for us to properly see the relationship. \n",
        "\n",
        "+ For COVID-19 forecasts, we performed univariate analysis on the historical data, which made me realize that historical data alone might not be sufficient for the prediction. But certainly, this is one of the main predictors and it can be used with other set of predictors to create a more powerful model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMEi8VFW77in"
      },
      "source": [
        "# Improvements That Can Be Done\n",
        "\n",
        "**Improvement:** Figure out another way to calculate Happiness Index of a country which includes more holistic and inclusive factors\n",
        "\n",
        "Based on the observations, we believe that factors apart from 6 selected need to be considered in order to make accurate happiness index scoring.  A possible improvement would be to research on an alternative way to calculate the index without using GDP per capita as a score \n",
        "\n",
        "**Improvement:** To move into using NLP & Decision Trees for analyzing Terrorism Data\n",
        "\n",
        "Most of the factors in the Terrorism Dataset were text based. Hence, using NLP here will be best for us to understand the influences of the predictor on the response. To improve model prediction, we believe models pertaining to Decision Trees will help. \n",
        "\n",
        "**Improvement:** To move into Multivariate Analysis\n",
        "\n",
        "We forecasted COVID-19 cases using only past data – however, we are aware that historical data alone is not enough to make accurate forecasts. There are many other external factors – the intention here is to more or less look at the trend and observe how this trend will move in the future. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk5F-RfI77in"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}